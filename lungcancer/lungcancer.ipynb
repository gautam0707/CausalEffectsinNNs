{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1bb3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import os,csv,math,sys, joblib\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import collections\n",
    "from joblib import Parallel, delayed\n",
    "import itertools\n",
    "import random\n",
    "import copy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sklearn.model_selection, sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "#import pydot\n",
    "import json\n",
    "import tqdm\n",
    "import matplotlib\n",
    "seed = 99 # To reproduce the results\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46c27ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"lungcancer_10000.csv\")\n",
    "dataset.drop(dataset.columns[[0]], axis=1, inplace=True)\n",
    "cols = dataset.columns\n",
    "for i in cols:\n",
    "    dataset[i] = dataset[i].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00d2fc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE for asia on dysp is 0.0\n",
      "ACE for tub on dysp is 1.0\n",
      "ACE for smoke on dysp is 1.0\n",
      "ACE for lung on dysp is 0.4911\n",
      "ACE for bronc on dysp is 0.9357\n",
      "ACE for either on dysp is 0.5467\n",
      "ACE for xray on dysp is 0.0\n"
     ]
    }
   ],
   "source": [
    "gt_aces = []\n",
    "\n",
    "#ACE of asia on dysp\n",
    "inp = np.array(dataset['asia']).reshape(-1,1)\n",
    "out = dataset['dysp']\n",
    "clf = LogisticRegression().fit(inp, out)\n",
    "do_value = np.ones([len(inp), 1])\n",
    "base_value = np.zeros([len(inp), 1])\n",
    "gt_aces.append(np.mean(clf.predict(do_value)) - np.mean(clf.predict(base_value)))\n",
    "print('ACE for asia on dysp is', np.mean(clf.predict(do_value)) - np.mean(clf.predict(base_value)))\n",
    "\n",
    "\n",
    "#ACE of Tub on dysp\n",
    "inp = np.array(dataset['tub']).reshape(-1,1)\n",
    "clf = LogisticRegression().fit(inp, out)\n",
    "do_value = np.ones([len(inp), 1])\n",
    "base_value = np.zeros([len(inp), 1])\n",
    "gt_aces.append(np.mean(clf.predict(do_value)) - np.mean(clf.predict(base_value)))\n",
    "print('ACE for tub on dysp is', np.mean(clf.predict(do_value)) - np.mean(clf.predict(base_value)))\n",
    "\n",
    "\n",
    "#ACE of Smoke on dysp\n",
    "inp = np.array(dataset['smoke']).reshape(-1,1)\n",
    "clf = LogisticRegression().fit(inp, out)\n",
    "do_value = np.ones([len(inp), 1])\n",
    "base_value = np.zeros([len(inp), 1])\n",
    "gt_aces.append(np.mean(clf.predict(do_value)) - np.mean(clf.predict(base_value)))\n",
    "print('ACE for smoke on dysp is', np.mean(clf.predict(do_value)) - np.mean(clf.predict(base_value)))\n",
    "\n",
    "\n",
    "#ACE of Lungcancer on dysp\n",
    "inp = np.array(dataset[['lung','smoke']]).reshape(-1,2)\n",
    "clf = LogisticRegression().fit(inp, out)\n",
    "do_value = pd.DataFrame.copy(dataset[['lung', 'smoke']])\n",
    "do_value['lung'] = 1\n",
    "do_value = np.array(do_value).reshape(-1,2)\n",
    "base_value = pd.DataFrame.copy(dataset[['lung', 'smoke']])\n",
    "base_value['lung'] = 0\n",
    "base_value = np.array(base_value).reshape(-1,2)\n",
    "gt_aces.append(np.mean(clf.predict(do_value)) - np.mean(clf.predict(base_value)))\n",
    "print('ACE for lung on dysp is', np.mean(clf.predict(do_value)) - np.mean(clf.predict(base_value)))\n",
    "\n",
    "\n",
    "#ACE of Bronc on dysp\n",
    "inp = np.array(dataset[['bronc','smoke','lung', 'either']]).reshape(-1,4)\n",
    "clf = LogisticRegression().fit(inp, out)\n",
    "do_value = pd.DataFrame.copy(dataset[['bronc', 'smoke', 'lung', 'either']])\n",
    "do_value['bronc'] = 1\n",
    "do_value = np.array(do_value).reshape(-1,4)\n",
    "base_value = pd.DataFrame.copy(dataset[['bronc', 'smoke', 'lung', 'either']])\n",
    "base_value['bronc'] = 0\n",
    "base_value = np.array(base_value).reshape(-1,4)\n",
    "gt_aces.append(np.mean(clf.predict(do_value)) - np.mean(clf.predict(base_value)))\n",
    "print('ACE for bronc on dysp is', np.mean(clf.predict(do_value)) - np.mean(clf.predict(base_value)))\n",
    "\n",
    "\n",
    "#ACE of Either on dysp\n",
    "inp = np.array(dataset[['either', 'lung', 'bronc', 'smoke']]).reshape(-1,4)\n",
    "clf = LogisticRegression().fit(inp, out)\n",
    "do_value = pd.DataFrame.copy(dataset[['either', 'lung', 'bronc', 'smoke']])\n",
    "do_value['either'] = 1\n",
    "do_value = np.array(do_value).reshape(-1,4)\n",
    "base_value = pd.DataFrame.copy(dataset[['either', 'lung', 'bronc', 'smoke']])\n",
    "base_value['either'] = 0\n",
    "base_value = np.array(base_value).reshape(-1,4)\n",
    "gt_aces.append(np.mean(clf.predict(do_value)) - np.mean(clf.predict(base_value)))\n",
    "print('ACE for either on dysp is', np.mean(clf.predict(do_value)) - np.mean(clf.predict(base_value)))\n",
    "\n",
    "\n",
    "#ACE of Xray on dysp\n",
    "gt_aces.append(np.mean([0.0]))\n",
    "print('ACE for xray on dysp is 0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe731ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./aces/aces_gt.npy',gt_aces,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc619671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class samp_network(nn.Module):\n",
    "    def __init__(self, input_size=1):\n",
    "        super().__init__()\n",
    "        self.input_size=input_size\n",
    "        self.fc1 = nn.Linear(self.input_size, 2)\n",
    "        self.fc2 = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9850b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#order of inputs: asia\ttub\tsmoke\tlung\tbronc\teither\txray\tdysp\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, feature_dim, batch_size=64, device='cpu',sample_size=50000):\n",
    "        super(Model, self).__init__()\n",
    "        self.batchsize=batch_size\n",
    "\n",
    "        self.causal_link_asia_tub = samp_network(input_size=1)\n",
    "        self.causal_link_either_xray = samp_network(input_size=1)\n",
    "        self.causal_link_smoke_bronc = samp_network(input_size=1)\n",
    "        self.causal_link_smoke_lung = samp_network(input_size=1)\n",
    "        self.causal_link_tub_lung_either = samp_network(input_size=2)\n",
    "\n",
    "        self.first_layer = nn.Linear(7,4)\n",
    "        self.second_layer = nn.Linear(4,2)\n",
    "        self.third_layer = nn.Linear(2,2)\n",
    "        self.regression_layer = nn.Linear(2, 1)\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "    def forward(self, inp, phase='freeze', inde=0, alpha=0):\n",
    "        if phase=='freeze':\n",
    "            x = F.relu(self.first_layer(inp))\n",
    "            x = F.relu(self.second_layer(x))\n",
    "            x = F.relu(self.third_layer(x))\n",
    "            prediction = self.regression_layer(x)\n",
    "            return prediction\n",
    "\n",
    "        elif phase=='train_dag':\n",
    "            asia_sample = inp[:,0].reshape(-1,1)\n",
    "            smoke_sample = inp[:,2].reshape(-1,1)\n",
    "            tub_sample = self.causal_link_asia_tub(asia_sample)\n",
    "            lung_sample = self.causal_link_smoke_lung(smoke_sample)\n",
    "            bronc_sample = self.causal_link_smoke_bronc(smoke_sample)\n",
    "            either_sample = self.causal_link_tub_lung_either(torch.cat((tub_sample, lung_sample), dim=1))\n",
    "            xray_sample = self.causal_link_either_xray(either_sample)\n",
    "            inp = torch.cat((asia_sample, tub_sample, smoke_sample, lung_sample, bronc_sample, either_sample, xray_sample),dim=1)\n",
    "            x = F.relu(self.first_layer(inp))\n",
    "            x = F.relu(self.second_layer(x))\n",
    "            x = F.relu(self.third_layer(x))\n",
    "            prediction = self.regression_layer(x)\n",
    "            return prediction, tub_sample, lung_sample, bronc_sample, either_sample, xray_sample \n",
    "\n",
    "        elif phase=='sample':\n",
    "            if inde == 0:\n",
    "                asia_sample = torch.tensor([alpha]*self.sample_size, dtype=torch.float).reshape(self.sample_size,-1)\n",
    "                smoke_sample = inp[:,2].reshape(self.sample_size,-1)\n",
    "                tub_sample = self.causal_link_asia_tub(torch.tensor(asia_sample, dtype=torch.float))\n",
    "                lung_sample = self.causal_link_smoke_lung(torch.tensor(smoke_sample, dtype=torch.float))\n",
    "                bronc_sample = self.causal_link_smoke_bronc(torch.tensor(smoke_sample, dtype=torch.float))\n",
    "                either_sample = self.causal_link_tub_lung_either(torch.cat((torch.tensor(tub_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float)), dim=1))\n",
    "                xray_sample = self.causal_link_either_xray(torch.tensor(either_sample, dtype=torch.float))\n",
    "                inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n",
    "                return inp\n",
    "\n",
    "            elif inde == 1:\n",
    "                asia_sample = inp[:,0].reshape(self.sample_size,-1)\n",
    "                smoke_sample = inp[:,2].reshape(self.sample_size,-1)\n",
    "                tub_sample = torch.tensor([alpha]*self.sample_size, dtype=torch.float).reshape(self.sample_size,-1)\n",
    "                lung_sample = self.causal_link_smoke_lung(torch.tensor(smoke_sample, dtype=torch.float))\n",
    "                bronc_sample = self.causal_link_smoke_bronc(torch.tensor(smoke_sample, dtype=torch.float))\n",
    "                either_sample = self.causal_link_tub_lung_either(torch.cat((torch.tensor(tub_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float)), dim=1))\n",
    "                xray_sample = self.causal_link_either_xray(torch.tensor(either_sample, dtype=torch.float))\n",
    "                inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n",
    "                return inp\n",
    "\n",
    "            elif inde == 2:\n",
    "                asia_sample = inp[:,0].reshape(self.sample_size,-1)\n",
    "                smoke_sample = torch.tensor([alpha]*self.sample_size, dtype=torch.float).reshape(self.sample_size,-1)\n",
    "                tub_sample = self.causal_link_asia_tub(torch.tensor(asia_sample, dtype=torch.float))\n",
    "                lung_sample = self.causal_link_smoke_lung(torch.tensor(smoke_sample, dtype=torch.float))\n",
    "                bronc_sample = self.causal_link_smoke_bronc(torch.tensor(smoke_sample, dtype=torch.float))\n",
    "                either_sample = self.causal_link_tub_lung_either(torch.cat((torch.tensor(tub_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float)), dim=1))\n",
    "                xray_sample = self.causal_link_either_xray(torch.tensor(either_sample, dtype=torch.float))\n",
    "                inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n",
    "                return inp\n",
    "\n",
    "            elif inde == 3:\n",
    "                asia_sample = inp[:,0].reshape(self.sample_size,-1)\n",
    "                smoke_sample = inp[:,2].reshape(self.sample_size,-1)\n",
    "                tub_sample = self.causal_link_asia_tub(torch.tensor(asia_sample, dtype=torch.float))\n",
    "                lung_sample = torch.tensor([alpha]*self.sample_size, dtype=torch.float).reshape(self.sample_size,-1)\n",
    "                bronc_sample = self.causal_link_smoke_bronc(torch.tensor(smoke_sample, dtype=torch.float))\n",
    "                either_sample = self.causal_link_tub_lung_either(torch.cat((torch.tensor(tub_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float)), dim=1))\n",
    "                xray_sample = self.causal_link_either_xray(torch.tensor(either_sample, dtype=torch.float))\n",
    "                inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n",
    "                return inp\n",
    "\n",
    "            elif inde == 4:\n",
    "                asia_sample = inp[:,0].reshape(self.sample_size,-1)\n",
    "                smoke_sample = inp[:,2].reshape(self.sample_size,-1)\n",
    "                tub_sample = self.causal_link_asia_tub(torch.tensor(asia_sample, dtype=torch.float))\n",
    "                lung_sample = self.causal_link_smoke_lung(torch.tensor(smoke_sample, dtype=torch.float))\n",
    "                bronc_sample = torch.tensor([alpha]*self.sample_size, dtype=torch.float).reshape(self.sample_size,-1)\n",
    "                either_sample = self.causal_link_tub_lung_either(torch.cat((torch.tensor(tub_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float)), dim=1))\n",
    "                xray_sample = self.causal_link_either_xray(torch.tensor(either_sample, dtype=torch.float))\n",
    "                inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n",
    "                return inp\n",
    "\n",
    "            elif inde == 5:\n",
    "                asia_sample = inp[:,0].reshape(self.sample_size,-1)\n",
    "                smoke_sample = inp[:,2].reshape(self.sample_size,-1)\n",
    "                tub_sample = self.causal_link_asia_tub(torch.tensor(asia_sample, dtype=torch.float))\n",
    "                lung_sample = self.causal_link_smoke_lung(torch.tensor(smoke_sample, dtype=torch.float))\n",
    "                bronc_sample = self.causal_link_smoke_bronc(torch.tensor(smoke_sample, dtype=torch.float))\n",
    "                either_sample = torch.tensor([alpha]*self.sample_size, dtype=torch.float).reshape(self.sample_size,-1)\n",
    "                xray_sample = self.causal_link_either_xray(torch.tensor(either_sample, dtype=torch.float))\n",
    "                inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n",
    "                return inp\n",
    "\n",
    "            elif inde == 6:\n",
    "                asia_sample = inp[:,0].reshape(self.sample_size,-1)\n",
    "                smoke_sample = inp[:,2].reshape(self.sample_size,-1)\n",
    "                tub_sample = self.causal_link_asia_tub(torch.tensor(asia_sample, dtype=torch.float))\n",
    "                lung_sample = self.causal_link_smoke_lung(torch.tensor(smoke_sample, dtype=torch.float))\n",
    "                bronc_sample = self.causal_link_smoke_bronc(torch.tensor(smoke_sample, dtype=torch.float))\n",
    "                either_sample = self.causal_link_tub_lung_either(torch.cat((torch.tensor(tub_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float)), dim=1))\n",
    "                xray_sample = torch.tensor([alpha]*self.sample_size, dtype=torch.float).reshape(self.sample_size,-1)\n",
    "                inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n",
    "                return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71380676",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_size=5 # to get mean and std values\n",
    "batch_size = 16\n",
    "\n",
    "values = list(dataset.columns.values)\n",
    "y = dataset[values[-1:]]\n",
    "y = np.array(y, dtype='float32')\n",
    "X = dataset[values[:-1]]\n",
    "X = np.array(X, dtype='float32')\n",
    "\n",
    "indices = np.random.choice(len(X), len(X), replace=False)\n",
    "X_values = X[indices]\n",
    "y_values = y[indices]\n",
    "\n",
    "# Creating a Train and a Test Dataset\n",
    "test_size = 2000\n",
    "val_size = 1000\n",
    "\n",
    "interval = 10\n",
    "epoch = 50\n",
    "\n",
    "X_test = X_values[-test_size:]\n",
    "X_trainval = X_values[:-test_size]\n",
    "X_val = X_trainval[-val_size:]\n",
    "X_train = X_trainval[:-val_size]\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "y_test = y_values[-test_size:]\n",
    "y_trainval = y_values[:-test_size]\n",
    "y_val = y_trainval[-val_size:]\n",
    "y_train = y_trainval[:-val_size]\n",
    "\n",
    "def binary_acc(pred, true):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == true).sum().float()\n",
    "    acc = correct_results_sum/true.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13fe1de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset to load data from csv file\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe1, dataframe2):\n",
    "        self.data_points = dataframe1\n",
    "        self.targets = dataframe2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_points)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_point = torch.tensor(np.array(self.data_points[idx]), dtype=torch.float)\n",
    "        target_point = torch.tensor(np.array(self.targets[idx]), dtype=torch.float)\n",
    "        return input_point, target_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d43f93f",
   "metadata": {},
   "source": [
    "# ERM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "595e3a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ensemble in range(ensemble_size):\n",
    "\n",
    "    # Interval / Epochs\n",
    "    \n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "    erm_model = Model(7,sample_size=len(dataset))\n",
    "    optimizer = optim.Adam([{'params': erm_model.parameters()}], lr = 0.001, weight_decay=1e-4)\n",
    "\n",
    "    for ep in range(0,epoch): \n",
    "        trainval = DataSet(X_train,y_train)\n",
    "        train_loader = DataLoader(trainval, batch_size=batch_size)\n",
    "        for input_data, target in train_loader:\n",
    "            erm_model.zero_grad()\n",
    "            output = erm_model(input_data)\n",
    "            loss = loss_func(output,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if ep%interval == 0:\n",
    "            print(ep, interval)\n",
    "            val = DataSet(X_val,y_val)\n",
    "            val_loader = DataLoader(val, batch_size=1)\n",
    "            acc_val = 0\n",
    "            acc_test = 0\n",
    "            \n",
    "            for input_data, target in val_loader:\n",
    "                output = erm_model(input_data)\n",
    "                acc = binary_acc(output, target.unsqueeze(1))\n",
    "                acc_val += acc\n",
    "\n",
    "            print ('validation accuracy:', float(acc_val/len(val_loader)))\n",
    "            testval = DataSet(X_test,y_test)\n",
    "            test_loader = DataLoader(testval, batch_size=1)\n",
    "            \n",
    "            for input_data, target in test_loader:\n",
    "                output = erm_model(input_data)\n",
    "                acc = binary_acc(output, target.unsqueeze(1))\n",
    "                acc_test += acc\n",
    "                \n",
    "            print('test accuracy:', float(acc_test/len(test_loader)))\n",
    "            print()\n",
    "    print(\"************\")\n",
    "    torch.save(erm_model, \"models/erm_lungcancer_\"+str(ensemble+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd2c306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 85.0999984741211\n",
      "test accuracy: 85.0999984741211\n",
      "test accuracy: 85.0999984741211\n",
      "test accuracy: 85.0999984741211\n",
      "test accuracy: 85.0999984741211\n"
     ]
    }
   ],
   "source": [
    "for ensemble in range(ensemble_size):\n",
    "    erm_model = torch.load(\"models/erm_lungcancer_\"+str(ensemble+1))\n",
    "    testval = DataSet(X_test,y_test)\n",
    "    test_loader = DataLoader(testval, batch_size=1)\n",
    "    acc_test = 0\n",
    "    for input_data, target in test_loader:\n",
    "        output = erm_model(input_data)\n",
    "        acc = binary_acc(output, target.unsqueeze(1))\n",
    "        acc_test += acc\n",
    "\n",
    "    print('test accuracy:', float(acc_test/len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5f0898",
   "metadata": {},
   "source": [
    "# Causal Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b6ae9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=1\n",
    "num_feat=7\n",
    "num_alpha=2\n",
    "\n",
    "cov = np.cov(X_values, rowvar=False)\n",
    "mean_vector = np.mean(X_values, axis=0)\n",
    "\n",
    "aces_ca_total = []\n",
    "\n",
    "for ensemble in range(ensemble_size):\n",
    "    ace_ca_total = []\n",
    "    model = torch.load(\"models/erm_lungcancer_\"+str(ensemble+1))\n",
    "    for output_index in range(0,n_classes):\n",
    "        for t in range(0,num_feat):\n",
    "            expectation_do_x = []\n",
    "            inp=copy.deepcopy(mean_vector)\n",
    "            for x in np.linspace(0, 1, num_alpha):                \n",
    "                inp[t] = x\n",
    "                input_torchvar = autograd.Variable(torch.FloatTensor(inp), requires_grad=True)\n",
    "                output=model(input_torchvar)\n",
    "                o1=output.data.cpu()\n",
    "                val=o1.numpy()[output_index]#first term in interventional expectation                                       \n",
    "\n",
    "                grad_mask_gradient = torch.zeros(n_classes)\n",
    "                grad_mask_gradient[output_index] = 1.0\n",
    "                #calculating the hessian\n",
    "                first_grads = torch.autograd.grad(output.cpu(), input_torchvar.cpu(), grad_outputs=grad_mask_gradient, retain_graph=True, create_graph=True)\n",
    "\n",
    "                for dimension in range(0,num_feat):#Tr(Hessian*Covariance)\n",
    "                    if dimension == t:\n",
    "                        continue\n",
    "                    temp_cov = copy.deepcopy(cov)\n",
    "                    temp_cov[dimension][t] = 0.0#row,col in covariance corresponding to the intervened one made 0\n",
    "                    grad_mask_hessian = torch.zeros(num_feat)\n",
    "                    grad_mask_hessian[dimension] = 1.0\n",
    "\n",
    "                    #calculating the hessian\n",
    "                    hessian = torch.autograd.grad(first_grads, input_torchvar, grad_outputs=grad_mask_hessian, retain_graph=True, create_graph=False)\n",
    "                    val += np.sum(0.5*hessian[0].data.numpy()*temp_cov[dimension])#adding second term in interventional expectation\n",
    "                expectation_do_x.append(val)#append interventional expectation for given interventional value\n",
    "            ace_ca_total.append(expectation_do_x[1] - expectation_do_x[0])\n",
    "    aces_ca_total.append(ace_ca_total)\n",
    "np.save('./aces/lungcancer_ca_total.npy',aces_ca_total,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f3d243d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse mean:  [0.07152004 0.79382408 0.99577005 0.44299555 0.73886312 0.40130374\n",
      " 0.03270478]\n",
      "rmse std:  [0.11000619 0.29897767 0.0166511  0.05895573 0.24109224 0.19264384\n",
      " 0.04140146]\n",
      "rmse all features mean:  0.49671162346976144\n",
      "rmse all features std:  0.13710403401181395\n"
     ]
    }
   ],
   "source": [
    "rmse_results = []\n",
    "\n",
    "for ensemble in range(ensemble_size):\n",
    "    rmse_results.append([rmse(gt_aces[0], aces_ca_total[ensemble][0]),\n",
    "                         rmse(gt_aces[1], aces_ca_total[ensemble][1]),\n",
    "                         rmse(gt_aces[2], aces_ca_total[ensemble][2]),\n",
    "                         rmse(gt_aces[3], aces_ca_total[ensemble][3]),\n",
    "                         rmse(gt_aces[4], aces_ca_total[ensemble][4]),\n",
    "                         rmse(gt_aces[5], aces_ca_total[ensemble][5]),\n",
    "                         rmse(gt_aces[6], aces_ca_total[ensemble][6])])\n",
    "    \n",
    "rmse_results = np.array(rmse_results)\n",
    "print(\"rmse mean: \", np.mean(rmse_results, axis=0))\n",
    "print(\"rmse std: \", np.std(rmse_results, axis=0))\n",
    "print(\"rmse all features mean: \", np.mean(np.mean(rmse_results, axis=0)))\n",
    "print(\"rmse all features std: \", np.mean(np.std(rmse_results, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b506b035",
   "metadata": {},
   "source": [
    "# CREDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b64cd162",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = {0:(lambda ii:0*ii), 1:(lambda ii:1*ii), 2:(lambda ii:1*ii),\n",
    "        3:(lambda ii:0.5*ii), 4:(lambda ii:1*ii), 5:(lambda ii:0.5*ii),\n",
    "        6:(lambda ii:0*ii)}\n",
    "\n",
    "def get_grad(x, prior):\n",
    "    a = x.clone().detach().requires_grad_(True)\n",
    "    for f in prior.keys():\n",
    "        z = prior[f]\n",
    "        z = torch.sum(z(a[0][f]), dim=0)\n",
    "        z.backward()\n",
    "    return a.grad\n",
    "\n",
    "def get_grads_to_match(ip, prior):\n",
    "    return get_grad(ip, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b013ee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n",
      "validation accuracy: 40.5\n",
      "test accuracy: 44.349998474121094\n",
      "\n",
      "10 10\n",
      "validation accuracy: 83.0\n",
      "test accuracy: 83.94999694824219\n",
      "\n",
      "20 10\n",
      "validation accuracy: 83.0\n",
      "test accuracy: 83.94999694824219\n",
      "\n",
      "30 10\n",
      "validation accuracy: 83.0\n",
      "test accuracy: 83.94999694824219\n",
      "\n",
      "40 10\n",
      "validation accuracy: 83.0\n",
      "test accuracy: 83.94999694824219\n",
      "\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "for ensemble in range(ensemble_size):\n",
    "\n",
    "    # Interval / Epochs\n",
    "    \n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "    credo_model = Model(7,sample_size=len(dataset))\n",
    "    optimizer = optim.Adam([{'params': credo_model.parameters()}], lr = 0.001, weight_decay=1e-4)\n",
    "\n",
    "    for ep in range(0,epoch): \n",
    "        trainval = DataSet(X_train,y_train)\n",
    "        train_loader = DataLoader(trainval, batch_size=64)\n",
    "        for input_data, target in train_loader:\n",
    "            credo_model.zero_grad()\n",
    "            input_data.requires_grad=True\n",
    "            output = credo_model(input_data)\n",
    "            \n",
    "            calc_grads = (autograd.grad(torch.sum(output, dim=0), input_data, retain_graph=True, create_graph=True)[0])\n",
    "            grads_to_match = get_grads_to_match(input_data, prior) \n",
    "            hinge_input = torch.abs(grads_to_match - calc_grads)\n",
    "            loss = loss_func(output,target) + 0.001 * torch.norm(torch.clamp(hinge_input, min=0), p=1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if ep%interval == 0:\n",
    "            print(ep, interval)\n",
    "            val = DataSet(X_val,y_val)\n",
    "            val_loader = DataLoader(val, batch_size=1)\n",
    "            acc_val = 0\n",
    "            acc_test = 0\n",
    "            \n",
    "            for input_data, target in val_loader:\n",
    "                output = credo_model(input_data)\n",
    "                acc = binary_acc(output, target.unsqueeze(1))\n",
    "                acc_val += acc\n",
    "\n",
    "            print ('validation accuracy:', float(acc_val/len(val_loader)))\n",
    "            testval = DataSet(X_test,y_test)\n",
    "            test_loader = DataLoader(testval, batch_size=1)\n",
    "            \n",
    "            for input_data, target in test_loader:\n",
    "                output = credo_model(input_data)\n",
    "                acc = binary_acc(output, target.unsqueeze(1))\n",
    "                acc_test += acc\n",
    "                \n",
    "            print('test accuracy:', float(acc_test/len(test_loader)))\n",
    "            print()\n",
    "    print(\"************\")\n",
    "    torch.save(credo_model, \"models/credo_lungcancer_\"+str(ensemble+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "029b176b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 83.94999694824219\n",
      "test accuracy: 83.94999694824219\n",
      "test accuracy: 83.94999694824219\n",
      "test accuracy: 84.69999694824219\n",
      "test accuracy: 83.94999694824219\n"
     ]
    }
   ],
   "source": [
    "for ensemble in range(ensemble_size):\n",
    "    credo_model = torch.load(\"models/credo_lungcancer_\"+str(ensemble+1))\n",
    "    testval = DataSet(X_test,y_test)\n",
    "    test_loader = DataLoader(testval, batch_size=1)\n",
    "    acc_test = 0\n",
    "    for input_data, target in test_loader:\n",
    "        output = credo_model(input_data)\n",
    "        acc = binary_acc(output, target.unsqueeze(1))\n",
    "        acc_test += acc\n",
    "\n",
    "    print('test accuracy:', float(acc_test/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "459217c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=1\n",
    "num_feat=7\n",
    "num_alpha=2\n",
    "\n",
    "cov = np.cov(X_values, rowvar=False)\n",
    "mean_vector = np.mean(X_values, axis=0)\n",
    "\n",
    "aces_credo_total = []\n",
    "\n",
    "for ensemble in range(ensemble_size):\n",
    "    ace_credo_total = []\n",
    "    model = torch.load(\"models/credo_lungcancer_\"+str(ensemble+1))\n",
    "    for output_index in range(0,n_classes):\n",
    "        for t in range(0,num_feat):\n",
    "            expectation_do_x = []\n",
    "            inp=copy.deepcopy(mean_vector)\n",
    "            for x in np.linspace(0, 1, num_alpha):                \n",
    "                inp[t] = x\n",
    "                input_torchvar = autograd.Variable(torch.FloatTensor(inp), requires_grad=True)\n",
    "                output=model(input_torchvar)\n",
    "                o1=output.data.cpu()\n",
    "                val=o1.numpy()[output_index]#first term in interventional expectation                                       \n",
    "\n",
    "                grad_mask_gradient = torch.zeros(n_classes)\n",
    "                grad_mask_gradient[output_index] = 1.0\n",
    "                #calculating the hessian\n",
    "                first_grads = torch.autograd.grad(output.cpu(), input_torchvar.cpu(), grad_outputs=grad_mask_gradient, retain_graph=True, create_graph=True)\n",
    "\n",
    "                for dimension in range(0,num_feat):#Tr(Hessian*Covariance)\n",
    "                    if dimension == t:\n",
    "                        continue\n",
    "                    temp_cov = copy.deepcopy(cov)\n",
    "                    temp_cov[dimension][t] = 0.0#row,col in covariance corresponding to the intervened one made 0\n",
    "                    grad_mask_hessian = torch.zeros(num_feat)\n",
    "                    grad_mask_hessian[dimension] = 1.0\n",
    "\n",
    "                    #calculating the hessian\n",
    "                    hessian = torch.autograd.grad(first_grads, input_torchvar, grad_outputs=grad_mask_hessian, retain_graph=True, create_graph=False)\n",
    "                    val += np.sum(0.5*hessian[0].data.numpy()*temp_cov[dimension])#adding second term in interventional expectation\n",
    "                expectation_do_x.append(val)#append interventional expectation for given interventional value\n",
    "            ace_credo_total.append(expectation_do_x[1] - expectation_do_x[0])\n",
    "    aces_credo_total.append(ace_credo_total)\n",
    "np.save('./aces/lungcancer_credo_total.npy',aces_credo_total,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5d9186de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse mean:  [5.44726849e-04 1.00003798e+00 9.99995661e-01 4.44970928e-01\n",
      " 3.78005159e-01 4.82776379e-01 4.29213047e-04]\n",
      "rmse std:  [4.29021338e-04 2.08854316e-04 6.65479930e-04 9.22940608e-02\n",
      " 2.40048627e-01 8.99921303e-02 3.26329729e-04]\n",
      "rmse all features mean:  0.47239429233823504\n",
      "rmse all features std:  0.06056635769639148\n"
     ]
    }
   ],
   "source": [
    "rmse_results = []\n",
    "\n",
    "for ensemble in range(ensemble_size):\n",
    "    rmse_results.append([rmse(gt_aces[0], aces_credo_total[ensemble][0]),\n",
    "                         rmse(gt_aces[1], aces_credo_total[ensemble][1]),\n",
    "                         rmse(gt_aces[2], aces_credo_total[ensemble][2]),\n",
    "                         rmse(gt_aces[3], aces_credo_total[ensemble][3]),\n",
    "                         rmse(gt_aces[4], aces_credo_total[ensemble][4]),\n",
    "                         rmse(gt_aces[5], aces_credo_total[ensemble][5]),\n",
    "                         rmse(gt_aces[6], aces_credo_total[ensemble][6])])\n",
    "\n",
    "mse_results = np.array(rmse_results)\n",
    "print(\"rmse mean: \", np.mean(rmse_results, axis=0))\n",
    "print(\"rmse std: \", np.std(rmse_results, axis=0))\n",
    "print(\"rmse all features mean: \", np.mean(np.mean(rmse_results, axis=0)))\n",
    "print(\"rmse all features std: \", np.mean(np.std(rmse_results, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "80c0ae3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n",
      "validation accuracy: 57.5\n",
      "test accuracy: 55.54999923706055\n",
      "\n",
      "0 5\n",
      "validation accuracy: 63.20000076293945\n",
      "test accuracy: 61.650001525878906\n",
      "\n",
      "5 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "5 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "10 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "10 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "15 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "15 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "0 5\n",
      "validation accuracy: 57.5\n",
      "test accuracy: 55.54999923706055\n",
      "\n",
      "0 5\n",
      "validation accuracy: 57.5\n",
      "test accuracy: 55.54999923706055\n",
      "\n",
      "5 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "5 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "10 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "10 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "15 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "15 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "0 5\n",
      "validation accuracy: 42.5\n",
      "test accuracy: 44.45000076293945\n",
      "\n",
      "0 5\n",
      "validation accuracy: 57.5\n",
      "test accuracy: 55.54999923706055\n",
      "\n",
      "5 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "5 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "10 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "10 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "15 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "15 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "0 5\n",
      "validation accuracy: 77.19999694824219\n",
      "test accuracy: 76.1500015258789\n",
      "\n",
      "0 5\n",
      "validation accuracy: 76.80000305175781\n",
      "test accuracy: 76.3499984741211\n",
      "\n",
      "5 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "5 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "10 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "10 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "15 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "15 5\n",
      "validation accuracy: 85.5\n",
      "test accuracy: 85.0999984741211\n",
      "\n",
      "0 5\n",
      "validation accuracy: 42.5\n",
      "test accuracy: 44.45000076293945\n",
      "\n",
      "0 5\n",
      "validation accuracy: 57.5\n",
      "test accuracy: 55.54999923706055\n",
      "\n",
      "5 5\n",
      "validation accuracy: 57.5\n",
      "test accuracy: 55.54999923706055\n",
      "\n",
      "5 5\n",
      "validation accuracy: 57.5\n",
      "test accuracy: 55.54999923706055\n",
      "\n",
      "10 5\n",
      "validation accuracy: 0.0\n",
      "test accuracy: 0.0\n",
      "\n",
      "10 5\n",
      "validation accuracy: 0.0\n",
      "test accuracy: 0.0\n",
      "\n",
      "15 5\n",
      "validation accuracy: 0.0\n",
      "test accuracy: 0.0\n",
      "\n",
      "15 5\n",
      "validation accuracy: 0.0\n",
      "test accuracy: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 91 # To reproduce the results\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "interval = 5\n",
    "epoch = 30\n",
    "for ensemble in range(5):\n",
    "    # Interval / Epochs\n",
    "    trainval = DataSet(X_train,y_train)\n",
    "    train_loader = DataLoader(trainval, batch_size=16)\n",
    "    \n",
    "    mse_loss_func = nn.MSELoss()\n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "    ahce_model = Model(7,sample_size=len(dataset))\n",
    "\n",
    "    optimizer = optim.Adam([{'params': ahce_model.parameters()}], lr = 0.001, weight_decay=1e-4)\n",
    "    losses = []\n",
    "    for i in range(1):\n",
    "        for ep in range(0,20):\n",
    "            for phase in ['freeze', 'train_dag']: \n",
    "                for input_data, target in train_loader:\n",
    "                    ahce_model.zero_grad()\n",
    "                    input_data.requires_grad=False\n",
    "                    if phase == 'freeze':\n",
    "                        output = ahce_model(input_data)\n",
    "                        loss = loss_func(output,target)\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    else:\n",
    "                        output, tub_sample, lung_sample, bronc_sample, either_sample, xray_sample  = ahce_model(input_data, phase='train_dag')\n",
    "                           \n",
    "                        lam_bda = 0\n",
    "                        loss = lam_bda*mse_loss_func(tub_sample, input_data[:,1])\n",
    "                        loss.backward(retain_graph=True)  \n",
    "\n",
    "                        loss = lam_bda*mse_loss_func(lung_sample, input_data[:,3])\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        \n",
    "                        loss = lam_bda*mse_loss_func(bronc_sample, input_data[:,4])\n",
    "                        loss.backward(retain_graph=True)\n",
    "\n",
    "                        loss = lam_bda*mse_loss_func(either_sample, input_data[:,5])\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        \n",
    "                        loss = lam_bda*torch.sqrt(mse_loss_func(xray_sample, input_data[:,6]))\n",
    "                        loss.backward(retain_graph=True)                   \n",
    "    \n",
    "                        loss = loss_func(output,target)\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        optimizer.step()\n",
    "\n",
    "                if ep%interval == 0:\n",
    "                    print(ep, interval)\n",
    "                    val = DataSet(X_val,y_val)\n",
    "                    val_loader = DataLoader(val, batch_size=1)\n",
    "                    acc_val = 0\n",
    "                    acc_test = 0\n",
    "\n",
    "                    for input_data, target in val_loader:\n",
    "                        output = ahce_model(input_data)\n",
    "                        acc = binary_acc(output, target.unsqueeze(1))\n",
    "                        acc_val += acc\n",
    "\n",
    "                    print ('validation accuracy:', float(acc_val/len(val_loader)))\n",
    "                    testval = DataSet(X_test,y_test)\n",
    "                    test_loader = DataLoader(testval, batch_size=1)\n",
    "\n",
    "                    for input_data, target in test_loader:\n",
    "                        output = ahce_model(input_data)\n",
    "                        acc = binary_acc(output, target.unsqueeze(1))\n",
    "                        acc_test += acc\n",
    "\n",
    "                    print('test accuracy:', float(acc_test/len(test_loader)))\n",
    "                    print()\n",
    "\n",
    "    torch.save(ahce_model, \"./models/ahce_lungcancer_\"+str(ensemble+1))\n",
    "#     torch.save(ahce_model, \"./models/ahce_lungcancer_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b89251fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble:  0\n",
      "feature:  0\n",
      "feature:  1\n",
      "feature:  2\n",
      "feature:  3\n",
      "feature:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5118/265272099.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tub_sample = self.causal_link_asia_tub(torch.tensor(asia_sample, dtype=torch.float))\n",
      "/tmp/ipykernel_5118/265272099.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  either_sample = self.causal_link_tub_lung_either(torch.cat((torch.tensor(tub_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float)), dim=1))\n",
      "/tmp/ipykernel_5118/265272099.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xray_sample = self.causal_link_either_xray(torch.tensor(either_sample, dtype=torch.float))\n",
      "/tmp/ipykernel_5118/265272099.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n",
      "/tmp/ipykernel_5118/265272099.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  either_sample = self.causal_link_tub_lung_either(torch.cat((torch.tensor(tub_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float)), dim=1))\n",
      "/tmp/ipykernel_5118/265272099.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xray_sample = self.causal_link_either_xray(torch.tensor(either_sample, dtype=torch.float))\n",
      "/tmp/ipykernel_5118/265272099.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n",
      "/tmp/ipykernel_5118/265272099.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lung_sample = self.causal_link_smoke_lung(torch.tensor(smoke_sample, dtype=torch.float))\n",
      "/tmp/ipykernel_5118/265272099.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bronc_sample = self.causal_link_smoke_bronc(torch.tensor(smoke_sample, dtype=torch.float))\n",
      "/tmp/ipykernel_5118/265272099.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  either_sample = self.causal_link_tub_lung_either(torch.cat((torch.tensor(tub_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float)), dim=1))\n",
      "/tmp/ipykernel_5118/265272099.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xray_sample = self.causal_link_either_xray(torch.tensor(either_sample, dtype=torch.float))\n",
      "/tmp/ipykernel_5118/265272099.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n",
      "/tmp/ipykernel_5118/265272099.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  either_sample = self.causal_link_tub_lung_either(torch.cat((torch.tensor(tub_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float)), dim=1))\n",
      "/tmp/ipykernel_5118/265272099.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xray_sample = self.causal_link_either_xray(torch.tensor(either_sample, dtype=torch.float))\n",
      "/tmp/ipykernel_5118/265272099.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n",
      "/tmp/ipykernel_5118/265272099.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  either_sample = self.causal_link_tub_lung_either(torch.cat((torch.tensor(tub_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float)), dim=1))\n",
      "/tmp/ipykernel_5118/265272099.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xray_sample = self.causal_link_either_xray(torch.tensor(either_sample, dtype=torch.float))\n",
      "/tmp/ipykernel_5118/265272099.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature:  5\n",
      "feature:  6\n",
      "ensemble:  1\n",
      "feature:  0\n",
      "feature:  1\n",
      "feature:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5118/265272099.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xray_sample = self.causal_link_either_xray(torch.tensor(either_sample, dtype=torch.float))\n",
      "/tmp/ipykernel_5118/265272099.py:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n",
      "/tmp/ipykernel_5118/265272099.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  either_sample = self.causal_link_tub_lung_either(torch.cat((torch.tensor(tub_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float)), dim=1))\n",
      "/tmp/ipykernel_5118/265272099.py:117: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inp = torch.cat((torch.tensor(asia_sample, dtype=torch.float), torch.tensor(tub_sample, dtype=torch.float), torch.tensor(smoke_sample, dtype=torch.float), torch.tensor(lung_sample, dtype=torch.float), torch.tensor(bronc_sample, dtype=torch.float), torch.tensor(either_sample, dtype=torch.float), torch.tensor(xray_sample, dtype=torch.float)),dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature:  3\n",
      "feature:  4\n",
      "feature:  5\n",
      "feature:  6\n",
      "ensemble:  2\n",
      "feature:  0\n",
      "feature:  1\n",
      "feature:  2\n",
      "feature:  3\n",
      "feature:  4\n",
      "feature:  5\n",
      "feature:  6\n",
      "ensemble:  3\n",
      "feature:  0\n",
      "feature:  1\n",
      "feature:  2\n",
      "feature:  3\n",
      "feature:  4\n",
      "feature:  5\n",
      "feature:  6\n",
      "ensemble:  4\n",
      "feature:  0\n",
      "feature:  1\n",
      "feature:  2\n",
      "feature:  3\n",
      "feature:  4\n",
      "feature:  5\n",
      "feature:  6\n"
     ]
    }
   ],
   "source": [
    "n_classes=1\n",
    "num_c=7#no. of features\n",
    "num_alpha=2\n",
    "\n",
    "aces_ahce_total = []\n",
    "for ensemble in range(5):\n",
    "    print(\"ensemble: \", ensemble)\n",
    "    ace_ahce_total = []\n",
    "    model =  torch.load(\"./models/ahce_lungcancer_\"+str(ensemble+1))\n",
    "    for output_index in range(0,n_classes):#For every class\n",
    "        #plt.figure()\n",
    "        for t in range(0,num_c):#For every feature\n",
    "            print(\"feature: \", t)\n",
    "            expectation_do_x = []\n",
    "            for x in np.linspace(0, 1, num_alpha):\n",
    "                X_values[:,t] = x\n",
    "                sample_data = model(X_values, phase='sample', inde=t, alpha=x).detach().numpy()\n",
    "                cov = np.cov(sample_data, rowvar=False)\n",
    "                means = np.mean(sample_data, axis=0)\n",
    "                cov=np.array(cov)\n",
    "                mean_vector = np.array(means)\n",
    "                inp=copy.deepcopy(mean_vector)\n",
    "                inp[t] = x\n",
    "                input_torchvar = autograd.Variable(torch.FloatTensor(inp), requires_grad=True)\n",
    "\n",
    "                output=model(input_torchvar)\n",
    "\n",
    "                o1=output.data.cpu()\n",
    "                val=o1.numpy()[output_index]#first term in interventional expectation                                       \n",
    "\n",
    "                grad_mask_gradient = torch.zeros(n_classes)\n",
    "                grad_mask_gradient[output_index] = 1.0\n",
    "                #calculating the hessian\n",
    "                first_grads = torch.autograd.grad(output.cpu(), input_torchvar.cpu(), grad_outputs=grad_mask_gradient, retain_graph=True, create_graph=True)\n",
    "\n",
    "                for dimension in range(0,num_c):#Tr(Hessian*Covariance)\n",
    "                    if dimension == t:\n",
    "                        continue\n",
    "                    temp_cov = copy.deepcopy(cov)\n",
    "                    temp_cov[dimension][t] = 0.0#row,col in covariance corresponding to the intervened one made 0\n",
    "                    grad_mask_hessian = torch.zeros(num_c)\n",
    "                    grad_mask_hessian[dimension] = 1.0\n",
    "\n",
    "                    #calculating the hessian\n",
    "                    hessian = torch.autograd.grad(first_grads, input_torchvar, grad_outputs=grad_mask_hessian, retain_graph=True, create_graph=False)\n",
    "                    val += np.sum(0.5*hessian[0].data.numpy()*temp_cov[dimension])#adding second term in interventional expectation\n",
    "                expectation_do_x.append(val)#append interventional expectation for given interventional value\n",
    "\n",
    "            ace_ahce_total.append(expectation_do_x[1] - expectation_do_x[0])\n",
    "\n",
    "    aces_ahce_total.append(ace_ahce_total)\n",
    "np.save('./aces/lungcancer_ahce_total.npy',aces_ahce_total,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "02dc9142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse mean:  [0.05796246 0.5865253  0.56491578 0.77649596 1.1145698  0.65574369\n",
      " 0.08098546]\n",
      "rmse std:  [0.06275573 0.29022294 0.33369286 0.75975439 0.51841772 0.2375601\n",
      " 0.12799542]\n",
      "rmse all features mean:  0.5481712078000819\n",
      "rmse all features std:  0.33291416532225815\n"
     ]
    }
   ],
   "source": [
    "rmse_results = []\n",
    "\n",
    "for ensemble in [0,1,2,3]:\n",
    "    rmse_results.append([rmse(gt_aces[0], aces_ahce_total[ensemble][0]),\n",
    "                         rmse(gt_aces[1], aces_ahce_total[ensemble][1]),\n",
    "                         rmse(gt_aces[2], aces_ahce_total[ensemble][2]),\n",
    "                         rmse(gt_aces[3], aces_ahce_total[ensemble][3]),\n",
    "                         rmse(gt_aces[4], aces_ahce_total[ensemble][4]),\n",
    "                         rmse(gt_aces[5], aces_ahce_total[ensemble][5]),\n",
    "                         rmse(gt_aces[6], aces_ahce_total[ensemble][6])])\n",
    "\n",
    "mse_results = np.array(rmse_results)\n",
    "print(\"rmse mean: \", np.mean(rmse_results, axis=0))\n",
    "print(\"rmse std: \", np.std(rmse_results, axis=0))\n",
    "print(\"rmse all features mean: \", np.mean(np.mean(rmse_results, axis=0)))\n",
    "print(\"rmse all features std: \", np.mean(np.std(rmse_results, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7b666e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse mean:  [0.05796246 0.5865253  0.56491578 0.77649596 1.1145698  0.65574369\n",
      " 0.08098546]\n",
      "rmse std:  [0.06275573 0.29022294 0.33369286 0.75975439 0.51841772 0.2375601\n",
      " 0.12799542]\n",
      "rmse all features mean:  0.5481712078000819\n",
      "rmse all features std:  0.33291416532225815\n"
     ]
    }
   ],
   "source": [
    "rmse_results = []\n",
    "\n",
    "for ensemble in [0,1,2,3]:\n",
    "    rmse_results.append([rmse(gt_aces[0], aces_ahce_total[ensemble][0]),\n",
    "                         rmse(gt_aces[1], aces_ahce_total[ensemble][1]),\n",
    "                         rmse(gt_aces[2], aces_ahce_total[ensemble][2]),\n",
    "                         rmse(gt_aces[3], aces_ahce_total[ensemble][3]),\n",
    "                         rmse(gt_aces[4], aces_ahce_total[ensemble][4]),\n",
    "                         rmse(gt_aces[5], aces_ahce_total[ensemble][5]),\n",
    "                         rmse(gt_aces[6], aces_ahce_total[ensemble][6])])\n",
    "\n",
    "mse_results = np.array(rmse_results)\n",
    "print(\"rmse mean: \", np.mean(rmse_results, axis=0))\n",
    "print(\"rmse std: \", np.std(rmse_results, axis=0))\n",
    "print(\"rmse all features mean: \", np.mean(np.mean(rmse_results, axis=0)))\n",
    "print(\"rmse all features std: \", np.mean(np.std(rmse_results, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c399f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
